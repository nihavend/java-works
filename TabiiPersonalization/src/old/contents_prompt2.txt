Write a complete Java program named MongoToPostgresContentExporter that migrates data from MongoDB collection "shows" to PostgreSQL table "contents" and its related tables.

Requirements:

-	use the below helpers
 
	import com.tabii.utils.CommonUtils;
	import com.tabii.utils.MongoProperties;
	import com.tabii.utils.PgProperties;

        MongoProperties mongoProperties = CommonUtils.getMongoConnectionProps();
        String mongoUri = mongoProperties.getMongoUri();
        String mongoDb = mongoProperties.getMongoDb();
        String mongoCollection = "shows"; // props.getProperty("mongo.collection", "shows");

        PgProperties pgProperties = CommonUtils.getPgConnectionProps();
        String pgUrl = pgProperties.getDbUrl();
        String pgUser = pgProperties.getDbUser();
        String pgPassword = pgProperties.getDbPassword();


1. Connect to MongoDB (URI, database, collection) and PostgreSQL (JDBC URL, user, password) using configuration properties.

2. PostgreSQL schema:
	-   contents
	    id BIGINT PRIMARY KEY,
	    title TEXT,
	    description TEXT,
	    spot TEXT,
	    made_year INTEGER,
	    content_type TEXT,
	    exclusive_badges JSONB,                -- now JSONB for better performance
	    created_at TIMESTAMPTZ DEFAULT NOW(),
	    updated_at TIMESTAMPTZ DEFAULT NOW()
   
   -    content_images
	    content_id BIGINT REFERENCES contents(id),
    	image_id INT REFERENCES images(id),
    	PRIMARY KEY (content_id, image_id)	

   -    images
    id SERIAL PRIMARY KEY,
    image_type TEXT,
    filename TEXT UNIQUE,
    title TEXT,
    url TEXT
	    
   - 	lookup_objects
    id BIGINT PRIMARY KEY,
    type TEXT NOT NULL NOT NULL,        -- e.g. genre, badge, category
    audit JSON,
    body JSON,
    fields JSON,
    isactive BOOLEAN,
    metadata JSON,
    path TEXT,
    paths JSON,
    published JSON,
    site TEXT,
    title TEXT,
    viewcount BIGINT,
    audit_user_id BIGINT,
    CONSTRAINT lookup_objects_audit_user_id_fkey FOREIGN KEY (audit_user_id)
        REFERENCES public.users (id) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
   		
   - 	content_lookup_relations
    id BIGSERIAL PRIMARY KEY,
    content_id BIGINT NOT NULL REFERENCES public.contents (id) ON DELETE CASCADE,
    lookup_object_id BIGINT NOT NULL REFERENCES public.lookup_objects (id) ON DELETE CASCADE,
    relation_type TEXT NOT NULL,     -- e.g. "genre", "badge", "category"
    created_at TIMESTAMPTZ DEFAULT NOW()


3. Query all documents from the MongoDB "shows" collection.

4. For each show document:

   a) Extract standard fields:
      - id (_id), title, description (from long_description) , contentType (from type), and nested fields inside "fields" (spot, made_year, etc.).
      - "made_year" or other numeric fields may use Mongo Extended JSON like:
        { "number": { "$numberLong": "2022" } }
        Handle this safely and return Integer or Long.
      - Use helper functions to extract typed values safely.

   b) Handle `exclusive_badge` array under "fields":
      - Transform to exclusive_badges JSON column in PostgreSQL as:
        { "exclusiveBadgeType": "originals" }
      - If missing, insert empty array "[]".

   c) Handle images:
      - Any nested document with `"type": "image"` (in fields or subfields)
        should map via filename to `images.filename`.
      - Insert `(content_id, image_id)` into `content_images` table.
      - Log missing images with their full JSON path.

   d) Handle lookup relations:
      - All lookup-related arrays (`genre`, `badges`, `exclusive_badge`, `parental-guide`, `age-restriction`, `category`) are members of the `fields` object.
      - For each item in these arrays, read `contentId.$numberLong` and use it to find `lookup_objects.typeid` in PostgreSQL.
      - Insert `(content_id, lookup_id)` into  `content_lookup_relations`
      - If related lookup record is missing, log a warning with full JSON path. relation_type column shuld be the type of object like badges

5. Use helper functions:
   - `getFieldValue(Document doc, String key, Class<?> type)`: safely returns value for any type (String, Integer, Long, Document → JSON).
   - `getLongFromDocument(Document doc, String key)`: parses nested `$numberLong` fields.
   - `transformExclusiveBadges(Object exclusiveBadgeObj)`: converts Mongo’s `exclusive_badge` array to simplified `exclusiveBadges` JSON array.
   - `flattenWithPaths(Document doc, String path)`: recursively traverses documents and logs full path for missing references.
   - `insertRelation(Connection conn, String table, String col1, String col2, Long id1, Long id2)`: inserts relation safely.

6. Use PreparedStatements for all PostgreSQL inserts and handle null values correctly.

7. Catch all exceptions and log warnings without stopping the export process.

8. Make the code compile-ready for Java 17+ and MongoDB Driver 4.11+.

9. Include structured logging that shows:
   - Missing image mappings
   - Missing lookup relations
   - Any unexpected field structure (with JSON path)


